{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install /kaggle/input/autocorrect/autocorrect-2.6.1.tar\nimport pandas as pd\nimport transformers\nfrom transformers import DebertaV2TokenizerFast, DebertaV2ForSequenceClassification\nimport torch\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torch.nn import MSELoss\nimport numpy as np\nimport random \nimport timeit\nfrom tqdm import tqdm\nimport autocorrect","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:32:50.720487Z","iopub.execute_input":"2023-09-20T02:32:50.720786Z","iopub.status.idle":"2023-09-20T02:33:39.294982Z","shell.execute_reply.started":"2023-09-20T02:32:50.720759Z","shell.execute_reply":"2023-09-20T02:33:39.293955Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=fb6d4fac21aaa2a51050791d87bcddc117cdb9ef456a69827f3b8f7f50079c5e\n  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\nSuccessfully installed autocorrect-2.6.1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"RANDOM_SEED = 42\nMODEL_PATH = \"/kaggle/input/debertav3base\"\nMAX_LENGTH = 512\nBATCH_SIZE = 8\nLEARNING_RATE = 2e-5\nEPOCHS = 2\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntransformers.utils.logging.set_verbosity_error()\nspell = autocorrect.Speller(lang=\"en\", fast=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:39.296886Z","iopub.execute_input":"2023-09-20T02:33:39.297236Z","iopub.status.idle":"2023-09-20T02:33:39.413825Z","shell.execute_reply.started":"2023-09-20T02:33:39.297204Z","shell.execute_reply":"2023-09-20T02:33:39.412846Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_summary_df = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\ntrain_prompt_df = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\ntest_summary_df = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\ntest_prompt_df = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:39.415620Z","iopub.execute_input":"2023-09-20T02:33:39.416201Z","iopub.status.idle":"2023-09-20T02:33:39.557829Z","shell.execute_reply.started":"2023-09-20T02:33:39.416165Z","shell.execute_reply":"2023-09-20T02:33:39.556878Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_summary_df[\"text\"] = train_summary_df[\"text\"].apply(lambda x: spell(x))\ntrain_summary_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:39.560312Z","iopub.execute_input":"2023-09-20T02:33:39.560587Z","iopub.status.idle":"2023-09-20T02:33:49.231157Z","shell.execute_reply.started":"2023-09-20T02:33:39.560563Z","shell.execute_reply":"2023-09-20T02:33:49.225762Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n3  005ab0199905    3b9047  The highest class was Pharaoh these people wer...   \n4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n\n    content   wording  \n0  0.205683  0.380538  \n1 -0.548304  0.506755  \n2  3.128928  4.231226  \n3 -0.210614 -0.471415  \n4  3.272894  3.219757  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaoh these people wer...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_prompt_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:49.235592Z","iopub.execute_input":"2023-09-20T02:33:49.235968Z","iopub.status.idle":"2023-09-20T02:33:49.266391Z","shell.execute_reply.started":"2023-09-20T02:33:49.235937Z","shell.execute_reply":"2023-09-20T02:33:49.258397Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   \n1    3b9047  In complete sentences, summarize the structure...   \n2    814d6b  Summarize how the Third Wave developed over su...   \n3    ebad26  Summarize the various ways the factory would u...   \n\n                prompt_title  \\\n0                 On Tragedy   \n1  Egyptian Social Structure   \n2             The Third Wave   \n3    Excerpt from The Jungle   \n\n                                         prompt_text  \n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n1  Egyptian society was structured like a pyramid...  \n2  Background \\r\\nThe Third Wave experiment took ...  \n3  With one member trimming beef in a cannery, an...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>814d6b</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_summary_df[\"text\"] = test_summary_df[\"text\"].apply(lambda x: spell(x))\ntest_summary_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:49.270394Z","iopub.execute_input":"2023-09-20T02:33:49.271143Z","iopub.status.idle":"2023-09-20T02:33:49.286055Z","shell.execute_reply.started":"2023-09-20T02:33:49.271104Z","shell.execute_reply":"2023-09-20T02:33:49.284665Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id            text\n0  000000ffffff    abc123  Example text 1\n1  111111eeeeee    def789  Example text 2\n2  222222cccccc    abc123  Example text 3\n3  333333dddddd    def789  Example text 4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>abc123</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111111eeeeee</td>\n      <td>def789</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222222cccccc</td>\n      <td>abc123</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>def789</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_prompt_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:49.287656Z","iopub.execute_input":"2023-09-20T02:33:49.288053Z","iopub.status.idle":"2023-09-20T02:33:49.297833Z","shell.execute_reply.started":"2023-09-20T02:33:49.288023Z","shell.execute_reply":"2023-09-20T02:33:49.296834Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text\n0    abc123    Summarize...  Example Title 1  Heading\\nText...\n1    def789    Summarize...  Example Title 2  Heading\\nText...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:49.299543Z","iopub.execute_input":"2023-09-20T02:33:49.300297Z","iopub.status.idle":"2023-09-20T02:33:49.315513Z","shell.execute_reply.started":"2023-09-20T02:33:49.300263Z","shell.execute_reply":"2023-09-20T02:33:49.314492Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     student_id  content  wording\n0  000000ffffff      0.0      0.0\n1  111111eeeeee      0.0      0.0\n2  222222cccccc      0.0      0.0\n3  333333dddddd      0.0      0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111111eeeeee</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222222cccccc</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = DebertaV2TokenizerFast.from_pretrained(MODEL_PATH)\nmodel = DebertaV2ForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=2).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:33:49.317170Z","iopub.execute_input":"2023-09-20T02:33:49.317607Z","iopub.status.idle":"2023-09-20T02:34:02.116681Z","shell.execute_reply.started":"2023-09-20T02:33:49.317573Z","shell.execute_reply":"2023-09-20T02:34:02.115754Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = train_prompt_df.merge(train_summary_df, on=\"prompt_id\")\ntrain_df[\"inputs\"] = train_df[\"prompt_question\"] + \" \" + train_df[\"prompt_title\"] + \" \" + tokenizer.sep_token + train_df[\"text\"]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.120990Z","iopub.execute_input":"2023-09-20T02:34:02.121280Z","iopub.status.idle":"2023-09-20T02:34:02.165487Z","shell.execute_reply.started":"2023-09-20T02:34:02.121255Z","shell.execute_reply":"2023-09-20T02:34:02.164613Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n3  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n4  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n\n                                                text   content   wording  \\\n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181   \n3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710   \n4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886   \n\n                                              inputs  \n0  Summarize at least 3 elements of an ideal trag...  \n1  Summarize at least 3 elements of an ideal trag...  \n2  Summarize at least 3 elements of an ideal trag...  \n3  Summarize at least 3 elements of an ideal trag...  \n4  Summarize at least 3 elements of an ideal trag...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0086ef22de8f</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n      <td>-0.970237</td>\n      <td>-0.417058</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0094589c7a22</td>\n      <td>Aristotle states that an ideal tragedy should ...</td>\n      <td>-0.387791</td>\n      <td>-0.584181</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00cd5736026a</td>\n      <td>One element of an Ideal tragedy is having a co...</td>\n      <td>0.088882</td>\n      <td>-0.594710</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00d98b8ff756</td>\n      <td>The 3 ideal of tragedy is how complex you need...</td>\n      <td>-0.687288</td>\n      <td>-0.460886</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df[\"inputs\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.166862Z","iopub.execute_input":"2023-09-20T02:34:02.167259Z","iopub.status.idle":"2023-09-20T02:34:02.175217Z","shell.execute_reply.started":"2023-09-20T02:34:02.167219Z","shell.execute_reply":"2023-09-20T02:34:02.174090Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle. On Tragedy [SEP]1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"},"metadata":{}}]},{"cell_type":"code","source":"test_df = test_prompt_df.merge(test_summary_df, on=\"prompt_id\")\ntest_df[\"inputs\"] = test_df[\"prompt_question\"] + \" \" + test_df[\"prompt_title\"] + \" \" + tokenizer.sep_token + test_df[\"text\"]\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.177019Z","iopub.execute_input":"2023-09-20T02:34:02.177811Z","iopub.status.idle":"2023-09-20T02:34:02.199661Z","shell.execute_reply.started":"2023-09-20T02:34:02.177774Z","shell.execute_reply":"2023-09-20T02:34:02.198728Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n\n             text                                            inputs  \n0  Example text 1  Summarize... Example Title 1 [SEP]Example text 1  \n1  Example text 3  Summarize... Example Title 1 [SEP]Example text 3  \n2  Example text 2  Summarize... Example Title 2 [SEP]Example text 2  \n3  Example text 4  Summarize... Example Title 2 [SEP]Example text 4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n      <td>Summarize... Example Title 1 [SEP]Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n      <td>Summarize... Example Title 1 [SEP]Example text 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>111111eeeeee</td>\n      <td>Example text 2</td>\n      <td>Summarize... Example Title 2 [SEP]Example text 2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>333333dddddd</td>\n      <td>Example text 4</td>\n      <td>Summarize... Example Title 2 [SEP]Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_length = train_df[\"inputs\"].apply(lambda x: len(x)).max()\nprint(max_length)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.201163Z","iopub.execute_input":"2023-09-20T02:34:02.201505Z","iopub.status.idle":"2023-09-20T02:34:02.212540Z","shell.execute_reply.started":"2023-09-20T02:34:02.201474Z","shell.execute_reply":"2023-09-20T02:34:02.211579Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"4151\n","output_type":"stream"}]},{"cell_type":"code","source":"s = train_df[\"inputs\"].str.len()\ns.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.214176Z","iopub.execute_input":"2023-09-20T02:34:02.214909Z","iopub.status.idle":"2023-09-20T02:34:02.236865Z","shell.execute_reply.started":"2023-09-20T02:34:02.214864Z","shell.execute_reply":"2023-09-20T02:34:02.235845Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"count    7165.000000\nmean      562.672994\nstd       318.629232\nmin       219.000000\n25%       355.000000\n50%       469.000000\n75%       667.000000\nmax      4151.000000\nName: inputs, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"class SummaryTrainDataset(Dataset):\n    def __init__(self, inputs, content, wording, tokenizer):\n        self.scores = torch.tensor([list(x) for x in zip(content, wording)])\n        self.encodings = tokenizer(inputs, padding=True, truncation=True, max_length=MAX_LENGTH)\n        \n    def __len__(self):\n        return len(self.scores)\n    \n    def __getitem__(self, idx):\n        out_dic = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        out_dic[\"scores\"] = self.scores[idx]\n        return out_dic\n    \nclass SummarySubmitDataset(Dataset):\n    def __init__(self, inputs, ids, tokenizer):\n        self.ids = ids\n        self.encodings = tokenizer(inputs, padding=True, truncation=True, max_length=MAX_LENGTH)\n        \n    def __len__(self):\n        return len(self.ids)\n    \n    def __getitem__(self, idx):\n        out_dic = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        out_dic[\"ids\"] = self.ids[idx]\n        return out_dic","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.239337Z","iopub.execute_input":"2023-09-20T02:34:02.239580Z","iopub.status.idle":"2023-09-20T02:34:02.250616Z","shell.execute_reply.started":"2023-09-20T02:34:02.239558Z","shell.execute_reply":"2023-09-20T02:34:02.249747Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset = SummaryTrainDataset(train_df[\"inputs\"].to_list(), train_df[\"content\"].to_list(), train_df[\"wording\"].to_list(), tokenizer)\nprint(\"-\"*30)\nprint(len(dataset))\nprint(dataset[0])\nprint(\"-\"*30)\n\ntest_dataset = SummarySubmitDataset(test_df[\"inputs\"].to_list(), test_df[\"student_id\"].to_list(), tokenizer)\nprint(len(test_dataset))\nprint(test_dataset[0])\nprint(\"-\"*30)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:02.252212Z","iopub.execute_input":"2023-09-20T02:34:02.252627Z","iopub.status.idle":"2023-09-20T02:34:05.226577Z","shell.execute_reply.started":"2023-09-20T02:34:02.252595Z","shell.execute_reply":"2023-09-20T02:34:05.225614Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"------------------------------\n7165\n{'input_ids': tensor([     1, 105982,    288,    668,    404,   2019,    265,    299,   1949,\n          8948,    261,    283,   1897,    293,  26446,    260,    589,  56195,\n             2,    376,   3036,    265,    299,   1949,   8948,    269,    272,\n           278,    403,    282,   6128,    277,    266,   1739,    741,    260,\n          1811,   3036,    265,    299,   1949,   8948,    269,    272,    278,\n           403,    364,    286,    311,    872,    889,    260,    279,    437,\n          3036,    265,    299,   1949,   8948,    269,    272,    278,    403,\n           286,    266,   1664,   3676,   4278,    263,    299,   3680,  21419,\n           270,    462,    397,    263,    966,    260,      2,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'scores': tensor([-0.2106, -0.4714])}\n------------------------------\n4\n{'input_ids': tensor([     1, 105982,    260,    260,    260,  11134,   7181,    376,      2,\n         11134,   1529,    376,      2]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'ids': '000000ffffff'}\n------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"generator = torch.Generator().manual_seed(RANDOM_SEED)\ntrain_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=generator)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:05.228097Z","iopub.execute_input":"2023-09-20T02:34:05.228455Z","iopub.status.idle":"2023-09-20T02:34:05.237528Z","shell.execute_reply.started":"2023-09-20T02:34:05.228422Z","shell.execute_reply":"2023-09-20T02:34:05.236574Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset=train_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=True)\n\nval_dataloader = DataLoader(dataset=val_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=True)\n\ntest_dataloader = DataLoader(dataset=test_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:05.238824Z","iopub.execute_input":"2023-09-20T02:34:05.239672Z","iopub.status.idle":"2023-09-20T02:34:05.250147Z","shell.execute_reply.started":"2023-09-20T02:34:05.239634Z","shell.execute_reply":"2023-09-20T02:34:05.249121Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = MSELoss(reduction=\"mean\")\n\nstart = timeit.default_timer()\nfor epoch in tqdm(range(EPOCHS), position=0, leave=True):\n    model.train()\n    train_running_loss = 0\n    for idx, sample in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n        input_ids = sample[\"input_ids\"].to(device)\n        attention_mask = sample[\"attention_mask\"].to(device)\n        targets = sample[\"scores\"].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = criterion(targets, outputs[\"logits\"])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_running_loss += loss.item()\n    train_loss = train_running_loss / (idx + 1)\n    \n    model.eval()\n    val_running_loss = 0\n    with torch.no_grad():\n        for idx, sample in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n            input_ids = sample[\"input_ids\"].to(device)\n            attention_mask = sample[\"attention_mask\"].to(device)\n            targets = sample[\"scores\"].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            \n            loss = criterion(targets, outputs[\"logits\"])\n            \n            val_running_loss += loss.item()\n        val_loss = val_running_loss / (idx + 1)\n        \n    print(\"-\"*30)\n    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n    print(\"-\"*30)\nstop = timeit.default_timer()\nprint(f\"Training Time: {stop-start:.2f}s\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:34:05.251576Z","iopub.execute_input":"2023-09-20T02:34:05.251976Z","iopub.status.idle":"2023-09-20T02:52:01.268365Z","shell.execute_reply.started":"2023-09-20T02:34:05.251945Z","shell.execute_reply":"2023-09-20T02:52:01.267389Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 807/807 [08:39<00:00,  1.55it/s]\n100%|██████████| 90/90 [00:19<00:00,  4.71it/s]\n 50%|█████     | 1/2 [08:58<08:58, 538.79s/it]","output_type":"stream"},{"name":"stdout","text":"------------------------------\nTrain Loss EPOCH 1: 0.3718\nValid Loss EPOCH 1: 0.2605\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 807/807 [08:38<00:00,  1.56it/s]\n100%|██████████| 90/90 [00:19<00:00,  4.71it/s]\n100%|██████████| 2/2 [17:55<00:00, 538.00s/it]","output_type":"stream"},{"name":"stdout","text":"------------------------------\nTrain Loss EPOCH 2: 0.2323\nValid Loss EPOCH 2: 0.2414\n------------------------------\nTraining Time: 1076.00s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T03:28:01.393854Z","iopub.execute_input":"2023-09-20T03:28:01.394226Z","iopub.status.idle":"2023-09-20T03:28:01.648041Z","shell.execute_reply.started":"2023-09-20T03:28:01.394197Z","shell.execute_reply":"2023-09-20T03:28:01.646894Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"contents = []\nwordings = []\nids = []\nmodel.eval()\nwith torch.no_grad():\n    for idx, sample in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n        input_ids = sample[\"input_ids\"].to(device)\n        attention_mask = sample[\"attention_mask\"].to(device)\n        ids.extend(sample[\"ids\"])\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)[\"logits\"]\n        \n        contents.extend([float(i) for i in outputs[:,0]])\n        wordings.extend([float(i) for i in outputs[:,1]])","metadata":{"execution":{"iopub.status.busy":"2023-09-20T03:32:39.907184Z","iopub.execute_input":"2023-09-20T03:32:39.907557Z","iopub.status.idle":"2023-09-20T03:32:39.946813Z","shell.execute_reply.started":"2023-09-20T03:32:39.907528Z","shell.execute_reply":"2023-09-20T03:32:39.945718Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 40.31it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df = pd.DataFrame(list(zip(ids, contents, wordings)),\n                            columns=[\"student_id\", \"content\", \"wording\"])\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T03:34:42.753425Z","iopub.execute_input":"2023-09-20T03:34:42.754386Z","iopub.status.idle":"2023-09-20T03:34:42.769179Z","shell.execute_reply.started":"2023-09-20T03:34:42.754347Z","shell.execute_reply":"2023-09-20T03:34:42.768102Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff -1.558995 -1.160506\n1  222222cccccc -1.591458 -1.214394\n2  111111eeeeee -1.568391 -1.172802\n3  333333dddddd -1.601415 -1.218777","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.558995</td>\n      <td>-1.160506</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.591458</td>\n      <td>-1.214394</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.568391</td>\n      <td>-1.172802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.601415</td>\n      <td>-1.218777</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}